1. 中央处理器
   1.1 cpu 由ALU和CP组成，算术逻辑单元负责对二进制数执行算术、比较、位运算；CU控制指令的顺序执行、通知ALU执行指令等；
   1.2 广义的处理器核心还包括MMU和Cache等功能模块；
   1.3 处理器体系结构
       (1) 冯诺依曼结构将程序治理存储器和数据存储器合并在一起，指令存储地址和数据存储地址指向同一个存储器的不同物理位置，因此程序指令和数据宽度相同；
       (2) 哈佛体系结构将指令和数据分开存储，可以有不同的数据宽度；还采用了独立的指令总线和数据总线，具有较高的处理器与存储器的通信执行效率；
       (3) 从指令集角度来看，中央处理器也可分为精简指令集计算机(RISC)和复杂指令集(CISC)计算机；

2. Cache
   2.1 Cache一般会用SRAM，而内存用的是DRAM；
   2.2 3级Cache一般是现代CPU的标配；L1～L3的效率是逐级递减，从几个cycle到几十个cycle；容量是逐级增大的，从几十KB到几十MB；
   2.3 处理器并不是对所有的内存地址都会用Cache，CPU中的MMU可以设置某些地址禁用Cache，具体是在物理地址转换中MMU会检查每个虚拟地址的访问权限；
   2.4 Cache Line
       (1) 处理器从内存读取数据过程：内存数据通过内部总线加载到Cache，然后再送到CPU内部寄存器；
       (2) 处理器写入内存数据过程：数据先从寄存器到Cache，再通过内部总线写入内存；
       (3) 上述读写操作都是以Cache Line为单位进行的，一般大小为32/64/128B；
       (4) 对于相同大小的数据结构，明显使用更少的Cache Line访问速度会更快；
       (5) 某些外设可以直接访问Cache (这取决于CPU的设计，外设本身其实访问的目标还是内存)， 但要求访问的地址必须按Cache Line对齐；
   2.5 Cache的写策略
       (1) 直写：写入Cache的同时也写入内存；总线占用高，效率不高；
       (2) 回写：只把数据写入Cache，并把对应的Cache Line标记为Dirty，只有在被标记Dirty的Cache Line要被新数据覆盖时，才将就数据写入内存；操作复杂；
   2.6 Cache 一致性
       (1) 缓存一致性：多核CPU中，每个核各自的L1/L2 Cache同时缓存了相同内存地址的数据，但彼此的内容不一样；   
       (2) 直写回写都会有 Cache一致性问题;
       (3) 解决方法：主要有两种 Snooping-based方案和Directory方案，都属于CPU内部的实现机制；
   2.7 三种Cache 操作指令
       (1) 在涉及处理器核和设备之间的数据交换时，在Cache和内存之间的数据也会存在一致性问题；
       (2) 在处理器和设备(无论是CPU芯片外部的设备，如网卡，还是CPU内部的设备，如各种控制器)交换数据的场景中，大多数情况，尤其是数据量特大时，程序会在内存申请两段缓存(buffer)；这两段缓存分别是数据发送缓存和数据接受缓存；
       (3) cpu上执行的程序在向设备发送数据时，先将数据写入数据发送buffer，再通知设备通过DMA操作读取数据；若是设备发送数据给程序，则先将数据写入数据接受buffer，在发起中断通知程序获取；
       (4) Cache的三种操作指令为Clean、Invalid、FLush; 都是避免缓存和内存buffer不一致的问题；还可通过配置MMU，针对数据缓存所在的内存地址范围禁用Cache功能；

3. NUMA (non-uniform mem access)
   3.1 在SMP(多核处理器)中，操作系统的加持下，无论程序运行在用户态还是内核态，都可以被分配到任意一个处理器核上运行；也即进程可以在不同的处理器核间移动，以达到负载平衡的效果；但存在一个问题：同一时间只能有一个处理器核访问计算机内存，会出现多个核在等待访问内存的情况；
   3.2 非统一内存访问(NUMA)提供分离的内存给处理器，大幅降低多个处理器核访问同一存储器时因等待产生的性能损失；
   3.3 任何一个处理器核都可访问所有的存储器，但要访问其他cpu芯片直连的存储器时，必须经过两个cpu芯片间的QPI总线；很明显访问直连的快；
   3.4 NUMA系统中的外设(如网卡) 也和存储器类似，分为直连和非直连，CPU访问直连网卡比访问非直连网卡速度更快。
 
